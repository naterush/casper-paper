\documentclass{article}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz-cd}
\usepackage{etoolbox}
\usepackage[]{algorithm2e}


\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }

\let\oldproofname=\proofname
\renewcommand\proofname{\bf{\oldproofname}}
\renewcommand\qedsymbol{$\blacksquare$}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{defn}{Definition}[section]

\newcommand{\notimplies}{%
  \mathrel{{\ooalign{\hidewidth$\not\phantom{=}$\hidewidth\cr$\implies$}}}}

\newcommand{\cat}{
  \mathbf
}
\newcommand{\domain}[1]{
  \mathrm{dom}(#1)
}
\newcommand{\codomain}[1]{
  \mathrm{cod}(#1)
}
\newcommand{\idarrow}[1][]{
  \mathrm{1}_{#1}
}

\AtBeginEnvironment{quote}{\singlespacing\small}

\setlength{\parskip}{1em}
\setlength{\parindent}{2em}


\begin{document}

\title{Casper research: \\ A specification of Casper the Friendly Ghost}
\maketitle

\begin{abstract}
We present a specification and limited experimental observations of a blockchain-based consensus protocol, ``Casper the Friendly Ghost.''

The protocol uses an adaptation of Y.\ Jompolovsky and A.\ Zohar's Greedy Heaviest Observed Sub-tree (GHOST) as a ``fork-choice rule.'' It is able to finalize/decide on blocks with asynchronous and Byzantine fault tolerant consensus safety. It allows blocks to be finalized while the network operates with the network overhead of the Bitcoin blockchain, with each node receiving $\mathcal{O}(1)$ messages/block. This is in contrast to the $\mathcal{O}(N)$ traditionally required for Byzantine fault tolerant state machine replication.

For pedagogical reasons, we first specify a binary consensus protocol (which decides on a bit, $0$ or $1$). This binary consensus protocol satisfies the same consensus safety proof as the blockchain consensus protocol and is therefore very similar to the blockchain consensus protocol.

\end{abstract}

\section{Introduction}

Consensus protocols are used by nodes in distributed systems to decide on the same consensus values, or on the same list of inputs to a replicated state machine. This is a challenging problem due to both network latency and the presence of faulty nodes. Arbitrary network latency, for example, means that nodes recieve distinct sets of messages, while the messages that they each receive may arrive in different orders. Faulty nodes may go offline, or they may behave in an arbitrary manner.

There are, roughly speaking, two broad classes of consensus protocols known today. One we refer to as ``traditional consensus.'' This class has its ``genetic roots'' in Paxos and multi-Paxos[CITE], and in the ``traditional'' consensus protocol research from the 80s and 90s[CITE]. The other we refer to as ``blockchain consensus.'' These are protocols that have their roots in the Bitcoin blockchain and Satoshi Nakamoto's whitepaper[CITE]. We first discuss the differences between these classes of protocols. Then we give an overview of the safety proof that the protocols found in this document satisfy, and finally we present the specifications of the protocols at hand.

\subsection{Comparing Traditional Consensus to Blockchain Consensus}

Traditional consensus protocols (such as multi-Paxos and pbft) are notoriously difficult to understand[CITE (http://paxos.systems/)]. Blockchain consensus protocols, on the other hand, are much more accessible. This difference comes at least in part from the relative simplicity of Bitcoin's specification[CITE].

In the context of state machine replication, traditional protocols decide (with irrevocable finality) on one ``block'' of state transitions/transactions to add to the shared operation log at a time. To decide on a block, a node must receive $\mathcal{O}(N)$ messages, where $N$ is the number of consensus-forming nodes.

Blockchain consensus protocols like Bitcoin do not finalize/decide on one block at a time. In fact, the Bitcoin blockchain in particular does not make ``finalized decisions'' at all; blocks are ``orphaned'' if/when they are not in the highest total difficulty chain. However, if the miners are able to mine on the same blockchain, then the blocks that get deep enough into the blockchain won't be reverted (``orphaned''). A block's depth in the blockchain therefore serves as a proxy for finalization. In the average case for blockchain consensus protocols, each node only requires approximately one message, $\mathcal{O}(1)$, for every block.

Traditional consensus protocol research has focused on producing protocols that are asynchronously safe (i.e.\ blocks won't be reverted due to arbitrary timing of future events) and live in asynchrony (or partial synchrony) (i.e.\ nodes eventually decide on new blocks). On the other hand, the Bitcoin blockchain is not safe or live in an asynchonous network but is safe and live (for unknown block-depth or ``confirmation count'') in a ``partially synchronous network.''

Traditional Byzantine fault tolerant consensus protocols have precisely stated Byzantine fault tolerance numbers (often can tolerate less than a third Byzantine faults, or up to $t$ faults when there are $3t + 1$ nodes)[CITE]. On the other hand, it is less clear exactly how many faults (measured as a proportion of hashrate) the Bitcoin blockchain protocol can tolerate[CITE].

\subsection{Overview of the Work Presented}

We give the specification of a consensus protocol, ``Casper the Friendly Ghost,'' which has both the low overhead of blockchain consensus protocols and the asynchronous Byzantine fault tolerant safety normally associated with traditional consensus protocols. However, before we share the blockchain consensus protocol, we give the specification of a binary consensus protocol (which chooses between $0$ and $1$ with asynchronous, Byzantine fault tolerant safety).

Understanding the binary consensus protocol makes it much easier to understand the blockchain consensus protocol; the protocols are remarkably similar. They are so similar because they are both ``generated'' in order to satisfy the same consensus safety proof.

This process for choosing the protocol specification is not specified or justified here, but rather in another, more abstract, paper[CITE]. This paper lacks information about \emph{why exactly} certain choices were made or \emph{how exactly} certain claims are proven. Even without the full scope of the ``process paper,'' our aim is to provide the reader with clear intuitions about why/how the blockchain protocol works. We therefore give a high level sketch of the safety proof which these protocols satisfy. Then, we present the promised protocols.

\subsection{Consensus Safety Proof}

Each of the protocols presented satisfies the same consensus safety proof. (And indeed, any consensus protocol generated by the correct-by-construction process\footnote{See our related paper -- PAPER} satisfies the same proof.)

We will assume that nodes running the consensus protocol have (local) states in $\Sigma$. These states have directional paths called ``protocol executions'' between them. We will write $\sigma \to \sigma'$ if there is an execution from $\sigma$ to $\sigma'$. Additionally, the paths are composable, so if $\sigma \to \sigma'$ and $\sigma' \to \sigma''$, then there is also an execution $\sigma \to \sigma''$.

The proof refers to an ``estimator,'' which maps protocol states to propositions about the consensus. In the binary consensus, the estimator maps protocol states to $0$ or $1$. In the blockchain consensus, on the other hand, the estimator maps from protocol states to a blockchain (functioning as our ``fork choice'').

An estimate in the binary consensus ($0$ or $1$) is said to be ``safe'' (have ``estimate safety'') for a particular protocol state if it is returned by the estimator on all future protocol states\footnote{Meaning, all states accessible from that state through any valid protocol execution}. In the blockchain consensus, a block is said to be ``safe'' for a particular protocol state if it is also in the fork choice for all future protocol states.

The consensus safety proof shows that decisions on safe estimates have consensus safety\footnote{Meaning, any decisions made on safe estimates by a protocol following node will be \emph{consistent} with decisions made on safe estimates by any other protocol following node} (as long as there are not more than $t$ Byzantine faults).

The proof relies on the following key result: If node $1$ with state $\sigma_1$ has safe estimate $e_1$ and another node $2$ with state $\sigma_2$ has safe estimate $e_2$, \emph{and if they have a future state in common $\sigma_3$}, then node $1$ and node $2$'s decisions on $e_1$ and $e_2$ are consistent. The result is quite simple as it follows without much work from the definition of estimate safety. Specifically, if a state $\sigma$ has a safe estimate $e$, then any future protocol state of $\sigma$, $\sigma'$, is also safe on $e$. So if our states $\sigma_1$ and $\sigma_2$ (with safety on $e_1$ and $e_2$) share a common future, then that future has to be safe on both $e_1$ \emph{and} $e_2$, which means that they are consistent. So this first part of the proof shows that decisions on safe estimates are consensus safe \emph{for any pair of nodes who have a future protocol state in common}.

Next we aim to construct protocols (``protocol states'' with ``state transitions'') which guarantee that nodes have common future protocol states unless there are more than $t$ Byzantine faults. Such a protocol has consensus safety if there are not more than $t$ such faults, from the result we just discussed. We accomplish this in a few steps.

First, we assume that protocol states are sets of protocol messages and then insist that the union $\sigma_1 \cup \sigma_2$ of any two protocol states $\sigma_1$ and $\sigma_2$ is itself a protocol state. Further, we insist that there is a state transition from each protocol state $\sigma$ to $\sigma' \supset \sigma$ (any superset of $\sigma$). This means that $\sigma_1 \cup \sigma_2$ is a protocol future of $\sigma_1$ and $\sigma_2$.

This assumption by itself allows for any two states to always have a common future state, which by itself guarantees consensus safety of decisions on safe estimates. But there's a problem: such a protocol fails to satisfy the \emph{non-triviality} property of consensus. Non-triviality means that the protocol is able to choose between mutually exclusive values. In our context, non-triviality means that there are two protocol states $\sigma_1$ and $\sigma_2$ that are each safe on two mutually exclusive estimates. Two protocol states with mutually exclusive safe estimates cannot have a common future, but we just insisted that $\sigma_1 \cup \sigma_2$ would be such a common future. This contradiction means that we have not yet satisfied non-triviality, as claimed.

Instead, we must be certain that $\sigma_1$ and $\sigma_2$ have common a future \emph{only as long as there are less than $t$ Byzantine faults in $\sigma_1 \cup \sigma_2$}. This allows for states without shared protocol futures (allowing non-triviality) but still allows for consensus safety from our previous result (although now only as long as there are less than $t$ Byzantine faults).

So our next step is to present a process that counts ``the number of Byzantine faults'' that are evidenced in any given protocol state. In the final step we define a ``new version'' of our initial protocol by excluding states with more than $t$ such faults, using the process from the previous step.

And indeed, both of the protocols specified here have the property that the union of any pair of protocol states $\sigma_1$ and $\sigma_2$, $\sigma_1 \cup \sigma_2$, is a protocol state if and only if it does not have more than $t$ Byzantine faults. Thus, two nodes who decide on safe estimates have consensus safety if there is less than $t$ Byzantine faults, and all this required saying almost nothing about the estimator! :)



\section{Casper the Friendly Binary Consensus}

In this section we specify the Binary consensus protocol by first defining protocol messages, and then defining the estimator (which maps sets of protocol messages to $0$ or $1$). Next, we give a way to detect and count Byzantine faults. Then we will define Casper the Friendly Binary Consensus' ``protocol states'' as sets of messages that exhibit up to $t$ Byzantine faults. Then we will define the protocol's ``state transitions''. Finally, we will be able to define binary estimate safety.  These definitions will satisfy those in the consensus safety proof for decisions on safe estimates.

The definition of ``protocol messages'' is parametric in a set of ``validator names'' $\mathcal{V}$, which are identified as the names of the consensus forming nodes.

Protocol messages have three parts. An ``estimate'' (a $0$ or a $1$), the ``sender'' (a validator name), and a ``justification''. The justification is itself a set protocol message. The idea with the protocol message definition is that the validators will use these messages to update each other on their current estimates. Further, the estimate values will not be arbitrary because a protocol message will only be ``valid'' only if ``estimate'' is the result of applying the estimator on the message's ``justification''. 

The definitions of the estimator and of validity will appear later. For now, we will denote the set of all possible protocol messages in the binary consensus protocol as $\mathcal{M}$, and define it as follows:

\begin{defn}[Protocol Messages, $\mathcal{M}$]
\begin{equation*}
\begin{split}
    \mathcal{M}_0 &= \{0, 1\} \times V \times \{\emptyset\}\\
    \mathcal{M}_n &= \{0, 1\} \times V \times \mathcal{P}(\bigcup_{i=0}^{n-1} \mathcal{M}_i)\\
    \mathcal{M} &= \lim_{n \to \infty} \bigcup_{i=0}^{n} \mathcal{M}_i
\end{split}
\end{equation*}
\end{defn}

$\mathcal{M}_0$ is the ``base case'', the set of messages with ``null justifications''. $\mathcal{M}_n$ is the set of messages at ``height'' $n$, which have messages of height $n-1$ (and/or lower) in their justification. Note that messages $\mathcal{M}_0$ have height $0$. $\mathcal{P}$ denotes the ``power set'' function, which maps sets to the set of all of their subsets, so $\mathcal{P}(\bigcup_{i=0}^{n-1} \mathcal{M}_i)$ denotes all sets of protocol messages at height $n$ or lower.
  
The estimator is a function that maps sets of protocol messages to $0$ or $1$, or a null value denoted by $\emptyset$:
  
\begin{equation*}
\begin{split}
    \mathcal{E}:\mathcal{P}(\mathcal{M}) \to \{0, 1\} \cup \{\emptyset\}
\end{split}
\end{equation*}

With the property that $\mathcal{E}(\emptyset) = \emptyset$. A protocol message $m$ is then said to be ``valid'' if either $\mathcal{E}(J(m)) = \emptyset$ or $E(m) = \mathcal{E}(J(m))$. From now on, we will assume that $\mathcal{M}$ only contains valid messages.\footnote{For readability, the process for finding the valid messages in $\mathcal{M}$ as originally defined is not described in the body of the paper, and instead is described in this footnote. All protocol messages at height $0$ are valid because they have null justifications and $\mathcal{E}(\emptyset) = \emptyset$ (and therefore these messages are valid). Then we can find the valid protocol messages at height $1$ by applying the estimator to their justifications (which are sets of [valid] messages at height 0) for each message, and only keeping valid message. Similarly, we can find the valid protocol messages at height $n$ by applying the estimator to the justification of these messages (which are sets of valid messages at height $h < n$). We are thereby able to collect all valid protocol messages and restrict $\mathcal{M}.$}


But before we can define the estimator, we need a few more basic definitions. We will want to define $E$, a ``helper function'' that picks out the ``estimate'' given in a protocol message:

$$
E(m) = e \iff m = (e, \_, \_)
$$

Similarly, we'll define $V$ as a function that picks out the ``sender'', and $J$ as a function that picks out the ``justification''.  

We say that message $m_1$ is ``a dependency'' of message $m_2$ and we write $m_1 \prec m_2$ if $m_1$ is in the justification of $m_2$, or if $m_1$ is in the justification of one of the messages in $m_1$'s justification, or if it is in the justification of a message in the justification of a message in the justification of $m_2$...

But we will also call $m_1$ a dependency of $m_2$ if $m_1 = m_2$:

\begin{defn}[dependency, $\prec$]
\begin{equation*}
\begin{split}
m_1 \prec m_2 \iff & m_1 = m_2 \text{ or } \exists m' \in J(m_2) \hspace{1mm} . \hspace{1mm} m' \prec m_2
\end{split}
\end{equation*}
\end{defn}

So we will define define ``the dependencies'' of a message $m$ as all of the messages $m'$ such that $m' \prec m$. These are all the messages that can be accessed in the justifications, or in the justification of messages in justifications... etc.

\begin{equation*}
\begin{split}
D(m) = &\{m\}\cup \bigcup_{m' \in J(m)} D(m') 
\end{split}
\end{equation*}

This definition can be extended in a natural way to define the dependencies of a set of messages (by taking the union of the dependencies of the individual messages).

If $m_1 \prec m_2$ then we will also say that $m_2$ is ``later'' than $m_1$ and write $m_2 \succ m_1$.

We now have the language to talk about the latest messages from a sender $v$ out of a set of messages $M$, which we denote as $L(v, M)$:

\begin{defn}[Latest message]
\begin{equation*}
\begin{split}
m \in L(v, M) \iff & \nexists m' \in D(M) \text{ such that } V(m') = v \text{ and } m' \succ m
\end{split}
\end{equation*}
\end{defn}

Latest messages will end up being critical to defining the estimator, which returns $0$ if ``more'' of the nodes have latest messages with estimate $0$ than with estimate $1$. We will use ``weights'' for nodes to measure which estimate has ``more'' consensus forming nodes, implemented by a map from validator names to positive real numbers. We do this without loss of generality (because it's possible that all weights are equal).

$$
W:V \to \mathbb{R}_+
$$


Now we can define the ``score'' of an estimate $e$ in a set of messages $M$ as the total weight of validators with latest messages with estimate $e$.

\begin{defn}[Score of a binary estimate]
\begin{align}
\text{Score}(e, M) = \sum_{\substack{v \in V \\ \text{such that } m \in L(v,M) \\ \text{with } E(m) = e}} W(v)
\end{align}
\end{defn}

Finally, we can define the estimator for the Binary consensus, it returns the estimate with the highest score, if there is one, otherwise it returns $\emptyset$.

\begin{defn}[Binary estimator]
\begin{align}
  \mathcal{E}(M) &= 0 &\text{ if } \text{Score}(0, M) > \text{Score}(1, M), \\
  \mathcal{E}(M) &= 1 &\text{ if } \text{Score}(1, M) > \text{Score}(0, M), \\
  \mathcal{E}(M) &= \emptyset &\text{ if } \text{Score}(1, M) = \text{Score}(0, M)
\end{align}
\end{defn}

So, at this stage we have protocol messages and an estimator. Now if we can come up with a way to count Byzantine faults from a set of protocol messages, then we will be ready to give the set of protocol states with their state transitions for a binary consensus protocol that tolerates $t$ Byzantine faults.

Each protocol message $m$ is supposed to represent a record of messages that were seen by validator $V(m)$. Any ``correct'' node will have a growing record of messages that they have received and sent. Specifically, correct nodes never be the sender of a pair of messages $m_1$ and $m_2$ such that neither $m_1 \prec m_2$ nor $m_1 \succ m_2$. We will call such a pair of messages ``an equivocation''.


\begin{defn}[Equivocation]
\begin{align}
Eq(m_1, m_2) \iff V(m_1) = V(m_2) \text{ and } m_1 \nsucc m_2 \text{ and } m_1 \nprec m_2
\end{align}
\end{defn}

A sender $v$ is said to be ``Byzantine'' in a set of protocol messages $M$:

$$
B(v,M) \iff \exists m_1, m_2 \in D(M) \text{ such that } \\ v = V(m_1) \land Eq(m_1, m_2)
$$

The weight of Byzantine faults evidenced in a set of messages $M$ is the sum of the weights of validators who are Byzantine in $M$.

\begin{align}
F(M) = \sum_{\substack{v \in V \\ B(v, M)}} W(v)
\end{align}

Then we can define a binary consensus protocol that tolerates $t$ Byzantine faults by using protocol states $\Sigma \subset \mathcal{P}(\mathcal{M}$) with the property that for any $\sigma \in \Sigma$, $F(\sigma) \leq t$ with protocol state transitions from any $\sigma$ to $\sigma'$ if $\sigma \subseteq \sigma'$. 

We can now give the definition of estimate safety for the Binary Consensus, for an estimate $e$ in a protocol state $\sigma$.

\begin{defn}[Binary Estimate Safety]
$$
S(e, \sigma) \iff \forall \sigma' \in \Sigma: \sigma \to \sigma' \implies e = \mathcal{E}(\sigma')
$$
\end{defn}

Because this construction satisifes the terms of our consensus safety proof, we know that decisions on such safe estimates in this protocol are consensus safe (if there are less than $t$ Byzantine faults (by weight)).

We have yet to talk about how nodes running the binary consensus protocol can detect when they are in a state with a safe estimate. We will get to this, however, we will first specify the blockchain consensus protocol because we will detect estimate safety in the same way, there.

But now that we've covered the binary consensus protocol, it will be a lot easier for us to specify the blockchain consensus protocol.


\section{Casper the Friendly Ghost}

The specification of Casper the Friendly Ghost is going to proceed along \emph{very} similar lines as Casper the Friendly Binary Consensus.

We will again first define the set of all protocol messages and then the estimator, which this time is going to be the Greedy Heaviest-observed Sub-tree (GHOST) ``fork choice rule''. Then, we will define protocol states as sets of messages which exhibit up to $t$ Byzantine faults, and then we define the protocol's ``state transitions''. Finally, we will be able to define block estimate safety. These definitions will satisfy those in the consensus safety proof for decisions on safe estimates.

Protocol messages are called ``blocks'' and have the same three components as the messages in the binary consensus protocol; an estimate, a sender and a justification. The estimate is a block, called ``the prevblock'' or ``the parent block''. For valid messages, the estimate will be the block on the head of the blockchain chosen by fork choice rule in the justification. The ``sender'' (a validator name) field is defined precisely as before. Finally, the justification is again simply a set of protocol messages.

So, to be more formal, in Casper the Friendly Ghost we have protocol messages, $\mathcal{M}$, with the following form (again parametric in a set of validator names, $\mathcal{V}$): 


\begin{defn}[Blocks]
\begin{equation*}
\begin{split}
  &\text{Genesis Block} = \{\emptyset\}\\
    &\mathcal{M}_0 = \{\text{Genesis Block}\} \times V \times \{\text{Genesis Block}\}\\
    &\mathcal{M}_n = \bigcup_{i=0}^{n-1} \mathcal{M}_i \times V \times \mathcal{P}(\bigcup_{i=0}^{n-1} \mathcal{M}_i)\\
    &\mathcal{M} = \{\text{Genesis Block}\} \cup \lim_{n \to \infty} \bigcup_{i=0}^{n} \mathcal{M}_i
\end{split}
\end{equation*}
\end{defn}

The definitions of the ``helper functions'' $E$, $V$, and $J$, and the definitions of ``dependency'', ``later'', ``latest messages'', and ``validator weights'' given in the previous section binary consensus also apply unchanged to the blockchain consensus. We will therefore use these here without giving the definitions again. 

We do need a couple of new terms, though, to define the fork choice rule. We will write $b_1 \downarrow b_2$ and say that block $b_1$ is ``in the blockchain'' of block $b_2$, if 

\begin{defn}[Blockchain membership, $b_1 \downarrow b_2$]
\begin{align}
  b_1 \downarrow b_2 &\iff b_1 = b_2 \text{ or } b_1 \downarrow E(b_2) 
\end{align}
\end{defn}

So now we define the ``score'' of a block $b$ given a set of protocol messages $M$ as the total weight of validators with latest blocks $b'$ such that $b \downarrow b'$.

\begin{defn}[Score of a block]
\begin{align}
\text{Score}(b, M) = \sum_{\substack{v \in V \\ m \in L(v,M) \\ b|E(m)}} W(v)
\end{align}
\end{defn}

The ``children'' of a block $b$ in a set of protocol messages $M$ are the blocks with $b$ as their prevblock.

$$
C(b,M) = \{b' \in M : E(b') = b\}
$$

We now have the language required to define the estimator for the blockchain consensus, the Greedy Heaviest-Observed Sub-Tree rule!
\begin{defn}[The Greedy Heaviest-Observed Sub-Tree (GHOST) fork-choice rule, $\mathcal{E}$]
\end{defn}

\begin{algorithm}[H]
 \KwData{A set of blocks $M$}
 \KwResult{The block at the head of the fork choice}
 $b$ = Genesis Block

 \While{$b$ has children ($C(b,M)$ is nonempty)}{
  scores = dict()

  \For{each child of block $b$, $b' \in C(b,M)$}{
  scores[$b'$] = $\text{Score}(b', M)$
  }
  \eIf{scores has a unique maximum}{
    $b$ = argmax(scores)
  }{
      $b$ = the max score block with the lowest hash
  }
}
\Return{b}

\caption{The Greedy Heaviest-Observed Sub-tree Fork-choice rule, $\mathcal{E}$}
\end{algorithm}

We are going to assume that ``hash'' has the property that out of any set of blocks, only one has the lowest hash. Using the hashes of blocks to eliminate ``ties'' means that the estimator for the blockchain consensus doesn't need to ever output an exception. Previously $\emptyset$ would be returned by the binary estimator, when $0$ and $1$ had the same score). This means that a message $m$ is valid if $E(m) = \mathcal{E}(J(m))$, and just as in the binary consensus we will insist that all the blocks are valid. \footnote{Following the process decribed in the footnote about excluding invalid messages from the binary consensus.}

Byzantine fault detection is defined here in \emph{precisely} the same way as in the binary consensus. We therefore don't give the definitions again. 

So we can alread define Casper the Friendly Ghost's protocol states $\Sigma \subset \mathcal{P}(\mathcal{M})$, which are sets of blocks that exhibit less than $t$ Byzantine faults, $F(M) < t$, for any $M \in \Sigma$.

We can now give the definition of estimate safety for Casper the Friendly Ghost, for a block $b$ in a protocol state $\sigma$.

\begin{defn}[Blockchain Estimate Safety]
$$
S(b, \sigma) \iff \forall \sigma' \in \Sigma: \sigma \to \sigma' \implies b \downarrow \mathcal{E}(\sigma')
$$
\end{defn}

Because this construction satisfies the terms of our consensus safety proof, we know that decisions on safe estimates in this protocol are consensus safe (if there are less than $t$ Byzantine faults (by weight)). 

We are now ready to give a mechanism that nodes can use to detect which of their estimates are safe, in the binary consensus and in the blockchain consensus.

\section{Safety Oracles}

\section{Validator Rotation}

\section{Liveness Considerations}

\end{document}